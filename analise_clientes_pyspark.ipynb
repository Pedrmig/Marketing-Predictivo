{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "749397f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotebook PySpark para Análise de Clientes, RFM, Clusterização, Recomendação e Churn.\\n'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notebook PySpark para Análise de Clientes, RFM, Clusterização, Recomendação e Churn.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ca721bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, count, isnan, when, trim, to_timestamp, datediff, current_date, unix_timestamp,col, udf, when\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, TimestampType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6cd78884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Inicializar SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Marketin-predictivo\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46298f43",
   "metadata": {},
   "source": [
    "2. Carregar os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "10581092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para os arquivos (ajuste se necessário)\n",
    "path_clientes = \"/home/jovyan/Marketing-Predictivo/CSV/clientes_anonimizados.csv\"\n",
    "path_produtos = \"/home/jovyan/Marketing-Predictivo/CSV/productos_con_atributos.csv\"\n",
    "path_ordens = \"/home/jovyan/Marketing-Predictivo/CSV/historico_ordenes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ef15f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jovyan/GitHub/Marketing-Predictivo/CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "753bc6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- user_registered: string (nullable = true)\n",
      " |-- user_status: integer (nullable = true)\n",
      " |-- billing_city: string (nullable = true)\n",
      " |-- billing_country: string (nullable = true)\n",
      " |-- billing_state: string (nullable = true)\n",
      "\n",
      "+-------+-------------------+-----------+------------+---------------+-------------+\n",
      "|user_id|user_registered    |user_status|billing_city|billing_country|billing_state|\n",
      "+-------+-------------------+-----------+------------+---------------+-------------+\n",
      "|4      |2024-04-05 15:38:09|0          |Lima        |PE             |LMA          |\n",
      "|8      |2024-04-12 16:09:39|0          |AREQUIPA    |PE             |ARE          |\n",
      "|10     |2024-04-12 17:03:18|0          |LIMA        |PE             |LIM          |\n",
      "|13     |2024-04-15 22:08:21|0          |Arequipa    |PE             |ARE          |\n",
      "|14     |2024-04-15 22:16:09|0          |NULL        |NULL           |NULL         |\n",
      "+-------+-------------------+-----------+------------+---------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clientes = spark.read.csv(path_clientes, header=True, inferSchema=True, sep=',')\n",
    "df_clientes.printSchema()\n",
    "df_clientes.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9279f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- custom_partnumber: string (nullable = true)\n",
      " |-- post_title: string (nullable = true)\n",
      " |-- post_excerpt: string (nullable = true)\n",
      " |-- _sku: string (nullable = true)\n",
      " |-- _price: float (nullable = true)\n",
      " |-- _regular_price: float (nullable = true)\n",
      " |-- _sale_price: float (nullable = true)\n",
      " |-- total_sales: integer (nullable = true)\n",
      " |-- _backorders: string (nullable = true)\n",
      " |-- _stock: float (nullable = true)\n",
      " |-- _stock_status: string (nullable = true)\n",
      " |-- minimum_allowed_quantity: string (nullable = true)\n",
      " |-- custom_condition: string (nullable = true)\n",
      " |-- custom_eta: string (nullable = true)\n",
      " |-- custom_moq: string (nullable = true)\n",
      " |-- _product_attributes: string (nullable = true)\n",
      " |-- pa_1: string (nullable = true)\n",
      " |-- pa_almacenamiento: string (nullable = true)\n",
      " |-- pa_color: string (nullable = true)\n",
      " |-- pa_condicion: string (nullable = true)\n",
      " |-- pa_disco-duro: string (nullable = true)\n",
      " |-- pa_emmc: string (nullable = true)\n",
      " |-- pa_garantia: string (nullable = true)\n",
      " |-- pa_marca: string (nullable = true)\n",
      " |-- pa_memoria-ram: string (nullable = true)\n",
      " |-- pa_pantalla: string (nullable = true)\n",
      " |-- pa_procesador: string (nullable = true)\n",
      " |-- pa_ram: string (nullable = true)\n",
      " |-- pa_sistema-operativo: string (nullable = true)\n",
      " |-- pa_tarjeta-de-video: string (nullable = true)\n",
      " |-- pa_teclado: string (nullable = true)\n",
      " |-- pa_unidad-solida: string (nullable = true)\n",
      "\n",
      "+----------+-----------------+--------------------+--------------------+-------------------+------+--------------+-----------+-----------+-----------+------+-------------+------------------------+----------------+----------+----------+--------------------+----+-----------------+--------+------------+-------------+-------+-----------+--------+--------------+-------------+-------------+------+--------------------+-------------------+----------+----------------+\n",
      "|product_id|custom_partnumber|          post_title|        post_excerpt|               _sku|_price|_regular_price|_sale_price|total_sales|_backorders|_stock|_stock_status|minimum_allowed_quantity|custom_condition|custom_eta|custom_moq| _product_attributes|pa_1|pa_almacenamiento|pa_color|pa_condicion|pa_disco-duro|pa_emmc|pa_garantia|pa_marca|pa_memoria-ram|  pa_pantalla|pa_procesador|pa_ram|pa_sistema-operativo|pa_tarjeta-de-video|pa_teclado|pa_unidad-solida|\n",
      "+----------+-----------------+--------------------+--------------------+-------------------+------+--------------+-----------+-----------+-----------+------+-------------+------------------------+----------------+----------+----------+--------------------+----+-----------------+--------+------------+-------------+-------+-----------+--------+--------------+-------------+-------------+------+--------------------+-------------------+----------+----------------+\n",
      "|       521|     NX.KJBAA.001|ACER ASPIRE A315-...|AMD RYZEN 3 7320U...|   NX.KJBAA.001-B1S|   0.0|           0.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|     7Dias|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|Plateado|       Nuevo|         NULL|   NULL|       NULL|    Acer|      8GB DDR4|15.6 Pulgadas|  AMD Ryzen 3|  NULL|          Windows 11|AMD RADEON GRAPHICS|      NULL|           128gb|\n",
      "|       524|     NX.KSJAA.004|ACER ASPIRE 3 A31...|AMD RYZEN 7 5700U...|       NX.KSJAA.004| 385.0|         385.0|       NULL|          7|         no|   0.0|   outofstock|                       1|           Nuevo|    7 DIAS|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|    Gris|       Nuevo|         NULL|   NULL|       NULL|    Acer|     16GB DDR4|15.6 Pulgadas|  AMD RYZEN 7|  NULL|          Windows 11|AMD RADEON GRAPHICS|      NULL|           512GB|\n",
      "|       528|        MGND3LL/A|APPLE MACBOOK AIR...|APPLE CHIP M1 OCT...|          MGND3LL/A| 650.0|         650.0|       NULL|          5|         no|   0.0|   outofstock|                       1|           Nuevo|    7 DIAS|         1|a:8:{s:8:\"pa_marc...|NULL|             NULL|  Dorado|       Nuevo|         NULL|   NULL|       NULL|   Apple|      8GB DDR4|13.3 Pulgadas|     Apple M1|  NULL|              MAC OS|               NULL|      NULL|           256GB|\n",
      "|       534|  M1603QA-R712512|ASUS VIVOBOOK M16...|AMD RYZEN 7 5800H...|M1603QA-R712512-B1S| 523.0|         523.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|   12 Dias|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|     12GB DDR4|  16 Pulgadas|  AMD RYZEN 7|  NULL|          Windows 11|AMD RADEON GRAPHICS|      NULL|           512GB|\n",
      "|       535|     M1605XA-EB96|ASUS VIVOBOOK M16...|AMD RYZEN 9 7940H...|   M1605XA-EB96-B1S| 738.0|         738.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|   14 DIAS|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|Plateado|       Nuevo|         NULL|   NULL|       NULL|    Asus|     16GB DDR5|  16 Pulgadas|  AMD RYZEN 9|  NULL|          Windows 11|AMD RADEON GRAPHICS|      NULL|             1TB|\n",
      "|       536|      L210MA-DS02|ASUS VIVOBOOK GO ...|INTEL CELERON N40...|    L210MA-DS02-B1S|   0.0|           0.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|     7Dias|         1|a:8:{s:8:\"pa_marc...|NULL|             NULL|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|      4GB DDR4|11.6 Pulgadas|Intel Celeron|  NULL|          Windows 11|               NULL|      NULL|            64GB|\n",
      "|       537|      L510MA-AS02|ASUS VIVOBOOK GO ...|INTEL CELERON N40...|    L510MA-AS02-B1S| 200.0|         200.0|       NULL|          0|         no| 204.0|      instock|                      10|           Nuevo|   13 Dias|        10|a:10:{s:8:\"pa_mar...|NULL|             64GB|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|      4GB DDR4|15.6 Pulgadas|Intel Celeron|  NULL|          Windows 11| INTEL UHD GRAPHICS|      NULL|            64GB|\n",
      "|       538|     F1504ZA-AS34|ASUS VIVOBOOK 15 ...|INTEL CORE I3 121...|   F1504ZA-AS34-B1S| 339.0|         339.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|     7Dias|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|    Azul|       Nuevo|         NULL|   NULL|       NULL|    Asus|      8GB DDR4|15.6 Pulgadas|Intel Core i3|  NULL|          Windows 11| INTEL UHD GRAPHICS|      NULL|           128gb|\n",
      "|       539|     F1500EA-WB51|ASUS VIVOBOOK 15 ...|INTEL CORE I5 113...|   F1500EA-WB51-B1S| 398.0|         398.0|       NULL|          0|         no|  59.0|      instock|                      10|           Nuevo|   13 Dias|        10|a:8:{s:8:\"pa_marc...|NULL|             NULL|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|      8GB DDR4|15.6 Pulgadas|Intel Core i5|  NULL|          Windows 11|               NULL|      NULL|           256GB|\n",
      "|       540|   TP3604VA-DS51T|ASUS VIVOBOOK 2-IN-1|INTEL CORE I5 135...| TP3604VA-DS51T-B1S| 617.0|         617.0|       NULL|          3|         no|   0.0|   outofstock|                       1|           Nuevo|   14 DIAS|         1|a:8:{s:8:\"pa_marc...|NULL|             NULL|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|      8GB DDR4|  16 Pulgadas|Intel Core i5|  NULL|          Windows 11|               NULL|      NULL|           512GB|\n",
      "+----------+-----------------+--------------------+--------------------+-------------------+------+--------------+-----------+-----------+-----------+------+-------------+------------------------+----------------+----------+----------+--------------------+----+-----------------+--------+------------+-------------+-------+-----------+--------+--------------+-------------+-------------+------+--------------------+-------------------+----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_produtos = spark.read.csv(path_produtos, header=True, inferSchema=False, sep=',', multiLine=True, escape='\"')\n",
    "df_produtos = df_produtos.withColumn(\"product_id\", col(\"product_id\").cast(IntegerType())) \\\n",
    "                       .withColumn(\"_price\", col(\"_price\").cast(FloatType())) \\\n",
    "                       .withColumn(\"_regular_price\", col(\"_regular_price\").cast(FloatType())) \\\n",
    "                       .withColumn(\"_sale_price\", col(\"_sale_price\").cast(FloatType())) \\\n",
    "                       .withColumn(\"total_sales\", col(\"total_sales\").cast(IntegerType())) \\\n",
    "                       .withColumn(\"_stock\", col(\"_stock\").cast(FloatType()))\n",
    "df_produtos.printSchema()\n",
    "df_produtos.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8758c01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------------+--------------------+-------------------+------+--------------+-----------+-----------+-----------+------+-------------+------------------------+----------------+----------+----------+--------------------+----+-----------------+--------+------------+-------------+-------+-----------+--------+--------------+-------------+-------------+------+--------------------+-------------------+----------+----------------+\n",
      "|product_id|custom_partnumber|          post_title|        post_excerpt|               _sku|_price|_regular_price|_sale_price|total_sales|_backorders|_stock|_stock_status|minimum_allowed_quantity|custom_condition|custom_eta|custom_moq| _product_attributes|pa_1|pa_almacenamiento|pa_color|pa_condicion|pa_disco-duro|pa_emmc|pa_garantia|pa_marca|pa_memoria-ram|  pa_pantalla|pa_procesador|pa_ram|pa_sistema-operativo|pa_tarjeta-de-video|pa_teclado|pa_unidad-solida|\n",
      "+----------+-----------------+--------------------+--------------------+-------------------+------+--------------+-----------+-----------+-----------+------+-------------+------------------------+----------------+----------+----------+--------------------+----+-----------------+--------+------------+-------------+-------+-----------+--------+--------------+-------------+-------------+------+--------------------+-------------------+----------+----------------+\n",
      "|       521|     NX.KJBAA.001|ACER ASPIRE A315-...|AMD RYZEN 3 7320U...|   NX.KJBAA.001-B1S|   0.0|           0.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|     7Dias|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|Plateado|       Nuevo|         NULL|   NULL|       NULL|    Acer|      8GB DDR4|15.6 Pulgadas|  AMD Ryzen 3|  NULL|          Windows 11|AMD RADEON GRAPHICS|      NULL|           128gb|\n",
      "|       524|     NX.KSJAA.004|ACER ASPIRE 3 A31...|AMD RYZEN 7 5700U...|       NX.KSJAA.004| 385.0|         385.0|       NULL|          7|         no|   0.0|   outofstock|                       1|           Nuevo|    7 DIAS|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|    Gris|       Nuevo|         NULL|   NULL|       NULL|    Acer|     16GB DDR4|15.6 Pulgadas|  AMD RYZEN 7|  NULL|          Windows 11|AMD RADEON GRAPHICS|      NULL|           512GB|\n",
      "|       528|        MGND3LL/A|APPLE MACBOOK AIR...|APPLE CHIP M1 OCT...|          MGND3LL/A| 650.0|         650.0|       NULL|          5|         no|   0.0|   outofstock|                       1|           Nuevo|    7 DIAS|         1|a:8:{s:8:\"pa_marc...|NULL|             NULL|  Dorado|       Nuevo|         NULL|   NULL|       NULL|   Apple|      8GB DDR4|13.3 Pulgadas|     Apple M1|  NULL|              MAC OS|               NULL|      NULL|           256GB|\n",
      "|       534|  M1603QA-R712512|ASUS VIVOBOOK M16...|AMD RYZEN 7 5800H...|M1603QA-R712512-B1S| 523.0|         523.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|   12 Dias|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|     12GB DDR4|  16 Pulgadas|  AMD RYZEN 7|  NULL|          Windows 11|AMD RADEON GRAPHICS|      NULL|           512GB|\n",
      "|       535|     M1605XA-EB96|ASUS VIVOBOOK M16...|AMD RYZEN 9 7940H...|   M1605XA-EB96-B1S| 738.0|         738.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|   14 DIAS|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|Plateado|       Nuevo|         NULL|   NULL|       NULL|    Asus|     16GB DDR5|  16 Pulgadas|  AMD RYZEN 9|  NULL|          Windows 11|AMD RADEON GRAPHICS|      NULL|             1TB|\n",
      "|       536|      L210MA-DS02|ASUS VIVOBOOK GO ...|INTEL CELERON N40...|    L210MA-DS02-B1S|   0.0|           0.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|     7Dias|         1|a:8:{s:8:\"pa_marc...|NULL|             NULL|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|      4GB DDR4|11.6 Pulgadas|Intel Celeron|  NULL|          Windows 11|               NULL|      NULL|            64GB|\n",
      "|       537|      L510MA-AS02|ASUS VIVOBOOK GO ...|INTEL CELERON N40...|    L510MA-AS02-B1S| 200.0|         200.0|       NULL|          0|         no| 204.0|      instock|                      10|           Nuevo|   13 Dias|        10|a:10:{s:8:\"pa_mar...|NULL|             64GB|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|      4GB DDR4|15.6 Pulgadas|Intel Celeron|  NULL|          Windows 11| INTEL UHD GRAPHICS|      NULL|            64GB|\n",
      "|       538|     F1504ZA-AS34|ASUS VIVOBOOK 15 ...|INTEL CORE I3 121...|   F1504ZA-AS34-B1S| 339.0|         339.0|       NULL|          0|         no|   0.0|   outofstock|                       1|           Nuevo|     7Dias|         1|a:9:{s:8:\"pa_marc...|NULL|             NULL|    Azul|       Nuevo|         NULL|   NULL|       NULL|    Asus|      8GB DDR4|15.6 Pulgadas|Intel Core i3|  NULL|          Windows 11| INTEL UHD GRAPHICS|      NULL|           128gb|\n",
      "|       539|     F1500EA-WB51|ASUS VIVOBOOK 15 ...|INTEL CORE I5 113...|   F1500EA-WB51-B1S| 398.0|         398.0|       NULL|          0|         no|  59.0|      instock|                      10|           Nuevo|   13 Dias|        10|a:8:{s:8:\"pa_marc...|NULL|             NULL|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|      8GB DDR4|15.6 Pulgadas|Intel Core i5|  NULL|          Windows 11|               NULL|      NULL|           256GB|\n",
      "|       540|   TP3604VA-DS51T|ASUS VIVOBOOK 2-IN-1|INTEL CORE I5 135...| TP3604VA-DS51T-B1S| 617.0|         617.0|       NULL|          3|         no|   0.0|   outofstock|                       1|           Nuevo|   14 DIAS|         1|a:8:{s:8:\"pa_marc...|NULL|             NULL|   Negro|       Nuevo|         NULL|   NULL|       NULL|    Asus|      8GB DDR4|  16 Pulgadas|Intel Core i5|  NULL|          Windows 11|               NULL|      NULL|           512GB|\n",
      "+----------+-----------------+--------------------+--------------------+-------------------+------+--------------+-----------+-----------+-----------+------+-------------+------------------------+----------------+----------+----------+--------------------+----+-----------------+--------+------------+-------------+-------+-----------+--------+--------------+-------------+-------------+------+--------------------+-------------------+----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_produtos.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "360e8fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_device_type: string (nullable = true)\n",
      " |-- order_session_visited_pages: integer (nullable = true)\n",
      " |-- order_session_start_time: string (nullable = true)\n",
      " |-- order_traffic_source_type: string (nullable = true)\n",
      " |-- order_utm_source_campaign: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- product_qty: integer (nullable = true)\n",
      " |-- product_net_revenue: double (nullable = true)\n",
      " |-- tax_amount: double (nullable = true)\n",
      " |-- product_gross_revenue: double (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n",
      "+--------+-------------------+-----------------+---------------------------+------------------------+-------------------------+-------------------------+----------+-----------+-----------+-------------------+----------+---------------------+------------+\n",
      "|order_id|order_date         |order_device_type|order_session_visited_pages|order_session_start_time|order_traffic_source_type|order_utm_source_campaign|product_id|customer_id|product_qty|product_net_revenue|tax_amount|product_gross_revenue|status      |\n",
      "+--------+-------------------+-----------------+---------------------------+------------------------+-------------------------+-------------------------+----------+-----------+-----------+-------------------+----------+---------------------+------------+\n",
      "|1918    |2024-04-16 23:14:42|Mobile           |98                         |2024-04-17 03:31:44     |referral                 |com.google.android.gm    |540       |29         |3          |1821.0             |327.78    |2148.78              |wc-completed|\n",
      "|2092    |2024-04-18 10:06:57|Desktop          |3                          |2024-04-18 14:20:47     |typein                   |(direct)                 |2082      |26         |5          |3090.0             |556.2     |3646.2               |wc-completed|\n",
      "|2289    |2024-04-18 17:45:10|Desktop          |10                         |2024-04-18 21:02:59     |typein                   |(direct)                 |2081      |72         |1          |1427.0             |256.86    |1683.86              |wc-completed|\n",
      "|2319    |2024-04-19 09:53:17|Desktop          |8                          |2024-04-19 14:47:29     |typein                   |(direct)                 |2221      |29         |2          |1582.0             |284.76    |1866.76              |wc-completed|\n",
      "|2392    |2024-04-19 15:12:21|Desktop          |20                         |2024-04-18 21:55:53     |typein                   |(direct)                 |2221      |26         |4          |3164.0             |569.52    |3733.52              |wc-completed|\n",
      "+--------+-------------------+-----------------+---------------------------+------------------------+-------------------------+-------------------------+----------+-----------+-----------+-------------------+----------+---------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ordens = spark.read.csv(path_ordens, header=True, inferSchema=True, sep=',')\n",
    "df_ordens.printSchema()\n",
    "df_ordens.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c2fb2d",
   "metadata": {},
   "source": [
    "3. Limpeza e Pré-processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5aad3",
   "metadata": {},
   "source": [
    "3.1 Dataset Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cc080a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-----------+------------+---------------+-------------+\n",
      "|user_id|user_registered|user_status|billing_city|billing_country|billing_state|\n",
      "+-------+---------------+-----------+------------+---------------+-------------+\n",
      "|      0|              0|          0|          13|             13|           14|\n",
      "+-------+---------------+-----------+------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar nulos\n",
    "df_clientes.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_clientes.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cf3a4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros antes da remoção de duplicatas (clientes): 253\n",
      "Registros após a remoção de duplicatas (clientes): 253\n"
     ]
    }
   ],
   "source": [
    "# Remover duplicatas baseadas em user_id\n",
    "print(f\"Registros antes da remoção de duplicatas (clientes): {df_clientes.count()}\")\n",
    "df_clientes = df_clientes.dropDuplicates(['user_id'])\n",
    "print(f\"Registros após a remoção de duplicatas (clientes): {df_clientes.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dbd095c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+-------------------+\n",
      "|user_id|    user_registered| user_registered_ts|dias_desde_registro|\n",
      "+-------+-------------------+-------------------+-------------------+\n",
      "|      4|2024-04-05 15:38:09|2024-04-05 15:38:09|                392|\n",
      "|      8|2024-04-12 16:09:39|2024-04-12 16:09:39|                385|\n",
      "|     10|2024-04-12 17:03:18|2024-04-12 17:03:18|                385|\n",
      "|     13|2024-04-15 22:08:21|2024-04-15 22:08:21|                382|\n",
      "|     14|2024-04-15 22:16:09|2024-04-15 22:16:09|                382|\n",
      "+-------+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizar coluna de data 'user_registered'\n",
    "df_clientes = df_clientes.withColumn(\"user_registered_ts\", to_timestamp(col(\"user_registered\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "# Calcular dias desde o registro (exemplo de normalização para ML)\n",
    "df_clientes = df_clientes.withColumn(\"dias_desde_registro\", datediff(current_date(), col(\"user_registered_ts\")))\n",
    "df_clientes.select(\"user_id\", \"user_registered\", \"user_registered_ts\", \"dias_desde_registro\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ea2de",
   "metadata": {},
   "source": [
    "3.2 Dataset Produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0fc48bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+----------+------------+----+------+--------------+-----------+-----------+-----------+------+-------------+------------------------+----------------+----------+----------+-------------------+----+-----------------+--------+------------+-------------+-------+-----------+--------+--------------+-----------+-------------+------+--------------------+-------------------+----------+----------------+\n",
      "|product_id|custom_partnumber|post_title|post_excerpt|_sku|_price|_regular_price|_sale_price|total_sales|_backorders|_stock|_stock_status|minimum_allowed_quantity|custom_condition|custom_eta|custom_moq|_product_attributes|pa_1|pa_almacenamiento|pa_color|pa_condicion|pa_disco-duro|pa_emmc|pa_garantia|pa_marca|pa_memoria-ram|pa_pantalla|pa_procesador|pa_ram|pa_sistema-operativo|pa_tarjeta-de-video|pa_teclado|pa_unidad-solida|\n",
      "+----------+-----------------+----------+------------+----+------+--------------+-----------+-----------+-----------+------+-------------+------------------------+----------------+----------+----------+-------------------+----+-----------------+--------+------------+-------------+-------+-----------+--------+--------------+-----------+-------------+------+--------------------+-------------------+----------+----------------+\n",
      "|         0|               66|         0|         163|  58|    57|            57|       5805|         24|         24|    25|           24|                      70|              78|        57|        65|                 59|5822|             5543|     772|         179|         5735|   5686|       2647|     130|          1954|       2503|         1959|  5821|                2113|               4640|      3951|            2508|\n",
      "+----------+-----------------+----------+------------+----+------+--------------+-----------+-----------+-----------+------+-------------+------------------------+----------------+----------+----------+-------------------+----+-----------------+--------+------------+-------------+-------+-----------+--------+--------------+-----------+-------------+------+--------------------+-------------------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_produtos.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_produtos.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a62b68b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|product_id|_sku|_price|\n",
      "+----------+----+------+\n",
      "|         0|  58|    57|\n",
      "+----------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_produtos.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in [\"product_id\", \"_sku\", \"_price\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "51d0c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros antes da remoção de duplicatas (produtos): 5823\n",
      "Registros após a remoção de duplicatas (produtos): 5823\n"
     ]
    }
   ],
   "source": [
    "# Remover duplicatas baseadas em product_id\n",
    "print(f\"Registros antes da remoção de duplicatas (produtos): {df_produtos.count()}\")\n",
    "df_produtos = df_produtos.dropDuplicates(['product_id'])\n",
    "print(f\"Registros após a remoção de duplicatas (produtos): {df_produtos.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7dfa6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpar colunas de texto (ex: remover espaços extras)\n",
    "if 'post_title' in df_produtos.columns:\n",
    "    df_produtos = df_produtos.withColumn(\"post_title_cleaned\", trim(col(\"post_title\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1535d7",
   "metadata": {},
   "source": [
    "3.3 Dataset Ordens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5b138ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------------------+------------------------+-------------------------+-------------------------+----------+-----------+-----------+-------------------+----------+---------------------+------+\n",
      "|order_id|order_date|order_device_type|order_session_visited_pages|order_session_start_time|order_traffic_source_type|order_utm_source_campaign|product_id|customer_id|product_qty|product_net_revenue|tax_amount|product_gross_revenue|status|\n",
      "+--------+----------+-----------------+---------------------------+------------------------+-------------------------+-------------------------+----------+-----------+-----------+-------------------+----------+---------------------+------+\n",
      "|       0|         0|              402|                        402|                     402|                        0|                      402|         0|          0|          0|                  0|         0|                    0|     0|\n",
      "+--------+----------+-----------------+---------------------------+------------------------+-------------------------+-------------------------+----------+-----------+-----------+-------------------+----------+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verificando Nulos\n",
    "df_ordens.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_ordens.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "527732e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros antes da remoção de duplicatas (ordens): 845\n",
      "Registros após a remoção de duplicatas (ordens): 845\n"
     ]
    }
   ],
   "source": [
    "# Remover duplicatas (considerar chave composta se necessário, ex: order_id, product_id)\n",
    "print(f\"Registros antes da remoção de duplicatas (ordens): {df_ordens.count()}\")\n",
    "df_ordens = df_ordens.dropDuplicates(['order_id', 'product_id'])\n",
    "print(f\"Registros após a remoção de duplicatas (ordens): {df_ordens.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9fed9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar colunas de data 'order_date', 'order_session_start_time'\n",
    "df_ordens = df_ordens.withColumn(\"order_date_ts\", to_timestamp(col(\"order_date\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "df_ordens = df_ordens.withColumn(\"session_start_ts\", to_timestamp(col(\"order_session_start_time\"), \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f669a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular recência da ordem em dias (será útil para RFM)\n",
    "df_ordens = df_ordens.withColumn(\"recencia_ordem_dias\", datediff(current_date(), col(\"order_date_ts\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "52a28f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter datas para Unix timestamp (outra forma de normalização para ML)\n",
    "df_ordens = df_ordens.withColumn(\"order_date_unix\", unix_timestamp(col(\"order_date_ts\")))\n",
    "df_ordens = df_ordens.withColumn(\"session_start_unix\", unix_timestamp(col(\"session_start_ts\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8b5727f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+-------------------+---------------+\n",
      "|order_id|         order_date|      order_date_ts|recencia_ordem_dias|order_date_unix|\n",
      "+--------+-------------------+-------------------+-------------------+---------------+\n",
      "|    1918|2024-04-16 23:14:42|2024-04-16 23:14:42|                381|     1713309282|\n",
      "|    2092|2024-04-18 10:06:57|2024-04-18 10:06:57|                379|     1713434817|\n",
      "|    2289|2024-04-18 17:45:10|2024-04-18 17:45:10|                379|     1713462310|\n",
      "|    2319|2024-04-19 09:53:17|2024-04-19 09:53:17|                378|     1713520397|\n",
      "|    2392|2024-04-19 15:12:21|2024-04-19 15:12:21|                378|     1713539541|\n",
      "+--------+-------------------+-------------------+-------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ordens.select(\"order_id\", \"order_date\", \"order_date_ts\", \"recencia_ordem_dias\", \"order_date_unix\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201c6c1",
   "metadata": {},
   "source": [
    "Próximos passos: Análise RFM, Clusterização, Recomendação, Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6c6fff",
   "metadata": {},
   "source": [
    "4. Análise RFM (Recência, Frequência, Monetário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e116c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, countDistinct, sum, min "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c510c",
   "metadata": {},
   "source": [
    "Data de referência para cálculo da recência (pode ser a data mais recente no dataset + 1 dia ou a data atual)\n",
    "Usaremos a data atual que já foi usada para calcular 'recencia_ordem_dias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c75f9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular Recência (R): Mínimo de dias desde a última compra por cliente\n",
    "rfm_r = df_ordens.groupBy(\"customer_id\") \\\n",
    "                 .agg(min(\"recencia_ordem_dias\").alias(\"Recencia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "83a0c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular Frequência (F): Número total de ordens distintas por cliente\n",
    "rfm_f = df_ordens.groupBy(\"customer_id\") \\\n",
    "                 .agg(countDistinct(\"order_id\").alias(\"Frequencia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "360cf248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular Monetário (M): Soma total do valor bruto gasto por cliente\n",
    "# Usando product_gross_revenue. Se preferir o valor líquido, use product_net_revenue\n",
    "rfm_m = df_ordens.groupBy(\"customer_id\") \\\n",
    "                 .agg(sum(\"product_gross_revenue\").alias(\"Monetario\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "52cb8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar R, F, M\n",
    "rfm_table = rfm_r.join(rfm_f, \"customer_id\", \"inner\") \\\n",
    "                 .join(rfm_m, \"customer_id\", \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4c1b2a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela RFM calculada:\n",
      "+-----------+--------+----------+------------------+\n",
      "|customer_id|Recencia|Frequencia|         Monetario|\n",
      "+-----------+--------+----------+------------------+\n",
      "|        737|     134|         2|           4715.28|\n",
      "|        516|     154|         1|            1044.3|\n",
      "|        580|     197|         2|            1770.0|\n",
      "|        513|     198|        13| 50761.23999999999|\n",
      "|        613|     210|         1|            1534.0|\n",
      "|        406|     199|         4| 9355.039999999999|\n",
      "|        587|     221|         1|            1451.4|\n",
      "|         26|     212|        53|218783.79999999996|\n",
      "|        501|     176|         5|          24134.54|\n",
      "|        577|     140|         1|             831.9|\n",
      "+-----------+--------+----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tabela RFM calculada:\")\n",
    "rfm_table.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b6db4dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuir Scores RFM (Exemplo: usando quantis)\n",
    "# Dividir cada métrica em N quantis (e.g., 5 quantis para scores de 1 a 5)\n",
    "from pyspark.ml.feature import QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa183fc",
   "metadata": {},
   "source": [
    "Scores: 1 (pior) a 5 (melhor). Recência: menor = melhor. Frequência/Monetário: maior = melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2795475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recência Score (menor é melhor, então inverte os labels)\n",
    "quantile_discretizer_r = QuantileDiscretizer(numBuckets=5, inputCol=\"Recencia\", outputCol=\"R_Score_temp\", relativeError=0.01)\n",
    "rfm_table = quantile_discretizer_r.fit(rfm_table).transform(rfm_table)\n",
    "rfm_table = rfm_table.withColumn(\"R_Score\", (5 - col(\"R_Score_temp\")).cast(IntegerType())) # Inverte para 5 ser o melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8f3dfa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequência Score (maior é melhor)\n",
    "quantile_discretizer_f = QuantileDiscretizer(numBuckets=5, inputCol=\"Frequencia\", outputCol=\"F_Score_temp\", relativeError=0.01)\n",
    "rfm_table = quantile_discretizer_f.fit(rfm_table).transform(rfm_table)\n",
    "rfm_table = rfm_table.withColumn(\"F_Score\", (col(\"F_Score_temp\") + 1).cast(IntegerType())) # Ajusta para 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "192a8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monetário Score (maior é melhor)\n",
    "quantile_discretizer_m = QuantileDiscretizer(numBuckets=5, inputCol=\"Monetario\", outputCol=\"M_Score_temp\", relativeError=0.01)\n",
    "rfm_table = quantile_discretizer_m.fit(rfm_table).transform(rfm_table)\n",
    "rfm_table = rfm_table.withColumn(\"M_Score\", (col(\"M_Score_temp\") + 1).cast(IntegerType())) # Ajusta para 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9788d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar Scores RFM (ex: concatenar como string ou somar)\n",
    "from pyspark.sql.functions import concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "32b64c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_final = rfm_table.withColumn(\"RFM_Score\", concat_ws(\"\", col(\"R_Score\"), col(\"F_Score\"), col(\"M_Score\")))\n",
    "rfm_final = rfm_final.select(\"customer_id\", \"Recencia\", \"Frequencia\", \"Monetario\", \"R_Score\", \"F_Score\", \"M_Score\", \"RFM_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "87a2a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela RFM final com Scores:\n",
      "+-----------+--------+----------+------------------+-------+-------+-------+---------+\n",
      "|customer_id|Recencia|Frequencia|         Monetario|R_Score|F_Score|M_Score|RFM_Score|\n",
      "+-----------+--------+----------+------------------+-------+-------+-------+---------+\n",
      "|        737|     134|         2|           4715.28|      5|      2|      3|      523|\n",
      "|        516|     154|         1|            1044.3|      4|      2|      2|      422|\n",
      "|        580|     197|         2|            1770.0|      3|      2|      2|      322|\n",
      "|        513|     198|        13| 50761.23999999999|      3|      4|      5|      345|\n",
      "|        613|     210|         1|            1534.0|      3|      2|      2|      322|\n",
      "|        406|     199|         4| 9355.039999999999|      3|      3|      4|      334|\n",
      "|        587|     221|         1|            1451.4|      2|      2|      2|      222|\n",
      "|         26|     212|        53|218783.79999999996|      3|      4|      5|      345|\n",
      "|        501|     176|         5|          24134.54|      4|      3|      4|      434|\n",
      "|        577|     140|         1|             831.9|      5|      2|      1|      521|\n",
      "+-----------+--------+----------+------------------+-------+-------+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tabela RFM final com Scores:\")\n",
    "rfm_final.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff34dfe",
   "metadata": {},
   "source": [
    "(Opcional) Salvar a tabela RFM\n",
    "rfm_final.write.parquet(\"/path/to/save/rfm_final.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363820c7",
   "metadata": {},
   "source": [
    "5. Clusterização de Clientes com K-Means (baseado em RFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "531ea4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4fac5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as colunas RFM para clusterização\n",
    "rfm_features = rfm_final.select(\"customer_id\", \"Recencia\", \"Frequencia\", \"Monetario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7f43e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar o vetor de features\n",
    "vec_assembler = VectorAssembler(inputCols=[\"Recencia\", \"Frequencia\", \"Monetario\"], outputCol=\"rfm_features_raw\")\n",
    "rfm_vector = vec_assembler.transform(rfm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bed72d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar as features (K-Means é sensível à escala)\n",
    "scaler = StandardScaler(inputCol=\"rfm_features_raw\", outputCol=\"features\", withStd=True, withMean=False)\n",
    "scaler_model = scaler.fit(rfm_vector)\n",
    "rfm_scaled = scaler_model.transform(rfm_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "85ddcd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features RFM montadas e escaladas:\n",
      "+-----------+------------------------------------------------------------+\n",
      "|customer_id|features                                                    |\n",
      "+-----------+------------------------------------------------------------+\n",
      "|737        |[2.1328196787611717,0.09615619884527073,0.06954858691027146]|\n",
      "|516        |[2.45115097409866,0.04807809942263536,0.01540302788177934]  |\n",
      "|580        |[3.1355632590742597,0.09615619884527073,0.02610682691827007]|\n",
      "|513        |[3.151479823841134,0.6250152924942597,0.7487089869134278]   |\n",
      "|613        |[3.342478601043627,0.04807809942263536,0.022625916662500727]|\n",
      "+-----------+------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Features RFM montadas e escaladas:\")\n",
    "rfm_scaled.select(\"customer_id\", \"features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cbfca445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo K-Means\n",
    "# Definir o número de clusters (k). Pode ser otimizado (ex: método do cotovelo ou silhouette)\n",
    "# Vamos começar com k=5 como exemplo\n",
    "k = 5\n",
    "kmeans = KMeans(featuresCol=\"features\", k=k, seed=1)\n",
    "model = kmeans.fit(rfm_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5780f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões (atribuir clusters aos clientes)\n",
    "predictions = model.transform(rfm_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ad869946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes atribuídos a 5 clusters:\n",
      "+-----------+----------+\n",
      "|customer_id|prediction|\n",
      "+-----------+----------+\n",
      "|        737|         0|\n",
      "|        516|         0|\n",
      "|        580|         0|\n",
      "|        513|         0|\n",
      "|        613|         4|\n",
      "|        406|         0|\n",
      "|        587|         4|\n",
      "|         26|         3|\n",
      "|        501|         0|\n",
      "|        577|         0|\n",
      "+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clientes atribuídos a {k} clusters:\")\n",
    "predictions.select(\"customer_id\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c4b9854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score com k=5: 0.5710270590536596\n"
     ]
    }
   ],
   "source": [
    "# Avaliar a clusterização (Silhouette Score)\n",
    "# Nota: Calcular Silhouette pode ser computacionalmente intensivo em datasets grandes\n",
    "evaluator = ClusteringEvaluator(featuresCol='features', metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(f\"Silhouette Score com k={k}: {silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ce4dcfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centróides dos Clusters (em escala original aproximada - requer desescalonamento):\n"
     ]
    }
   ],
   "source": [
    "# (Opcional) Explorar os centróides dos clusters\n",
    "print(\"Centróides dos Clusters (em escala original aproximada - requer desescalonamento):\")\n",
    "centers = model.clusterCenters()\n",
    "# Desescalonar os centros (aproximado, pois não armazenamos a média se withMean=True fosse usado)\n",
    "# scaler_model.std é o desvio padrão usado\n",
    "# original_center = scaled_center * std_dev\n",
    "# print(scaler_model.std)\n",
    "# for i, center in enumerate(centers):\n",
    "#     # Precisa aplicar a transformação inversa do scaler\n",
    "#     # Isso é mais complexo, pois StandardScaler não tem um 'inverse_transform' direto em PySpark ML\n",
    "#     # Vamos mostrar os centros escalados por enquanto\n",
    "#     print(f\"Cluster {i}: {center}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ff9822af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar as previsões de cluster com a tabela RFM final\n",
    "clientes_clusterizados = rfm_final.join(predictions.select(\"customer_id\", col(\"prediction\").alias(\"cluster\")), \"customer_id\", \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "55e7f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela final com RFM Scores e Cluster:\n",
      "+-----------+--------+----------+------------------+-------+-------+-------+---------+-------+\n",
      "|customer_id|Recencia|Frequencia|         Monetario|R_Score|F_Score|M_Score|RFM_Score|cluster|\n",
      "+-----------+--------+----------+------------------+-------+-------+-------+---------+-------+\n",
      "|         26|     212|        53|218783.79999999996|      3|      4|      5|      345|      3|\n",
      "|         29|     151|        26| 72460.25999999998|      4|      4|      5|      445|      3|\n",
      "|         30|     189|        19|43949.100000000006|      3|      4|      5|      345|      0|\n",
      "|         43|     146|        27|          65978.52|      4|      4|      5|      445|      3|\n",
      "|         60|     197|        30|          79364.44|      3|      4|      5|      345|      3|\n",
      "|         69|     358|         1|            1439.6|      1|      2|      2|      122|      2|\n",
      "|         72|     379|         1|           1683.86|      1|      2|      2|      122|      2|\n",
      "|         75|     252|         5|           16449.2|      2|      3|      4|      234|      4|\n",
      "|         80|     142|        24|         152726.22|      4|      4|      5|      445|      3|\n",
      "|        119|     135|        34|          91871.26|      5|      4|      5|      545|      3|\n",
      "+-----------+--------+----------+------------------+-------+-------+-------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tabela final com RFM Scores e Cluster:\")\n",
    "clientes_clusterizados.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8574e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e3c64ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Análise das características médias por cluster:\n",
      "+-------+------------------+------------------+------------------+------------+\n",
      "|cluster|    Recencia_Media|  Frequencia_Media|   Monetario_Medio|Num_Clientes|\n",
      "+-------+------------------+------------------+------------------+------------+\n",
      "|      0|162.75757575757575| 6.575757575757576| 17486.52727272728|          33|\n",
      "|      1|             130.0|             172.0| 528263.5800000001|           1|\n",
      "|      2| 316.2307692307692|1.0769230769230769|1704.3738461538462|          13|\n",
      "|      3|171.55555555555554|28.444444444444443|106955.37310666667|           9|\n",
      "|      4|237.41666666666666|2.4166666666666665|7017.2633333333315|          24|\n",
      "+-------+------------------+------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analisar as características de cada cluster\n",
    "print(\"\\nAnálise das características médias por cluster:\")\n",
    "clientes_clusterizados.groupBy(\"cluster\") \\\n",
    "    .agg(avg(\"Recencia\").alias(\"Recencia_Media\"), \\\n",
    "         avg(\"Frequencia\").alias(\"Frequencia_Media\"), \\\n",
    "         avg(\"Monetario\").alias(\"Monetario_Medio\"), \\\n",
    "         countDistinct(\"customer_id\").alias(\"Num_Clientes\")) \\\n",
    "    .orderBy(\"cluster\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d0aae",
   "metadata": {},
   "source": [
    "(Opcional) Salvar os resultados da clusterização\n",
    "clientes_clusterizados.write.parquet(\"/path/to/save/clientes_clusterizados.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5adaa6",
   "metadata": {},
   "source": [
    "6. Modelo de Recomendação de Produtos (ALS - Collaborative Filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e85d294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c10a608",
   "metadata": {},
   "source": [
    "Preparar dados para ALS: user_id, product_id, rating\n",
    "Usaremos 'customer_id' como user, 'product_id' como item.\n",
    "Como não temos ratings explícitos, podemos usar a frequência de compra (product_qty) ou simplesmente 1 para indicar interação.\n",
    "Usar 1 é mais simples e comum para dados implícitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "674e88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certificar que os IDs são inteiros e não nulos\n",
    "als_data = df_ordens.select(\n",
    "    col(\"customer_id\").cast(IntegerType()),\n",
    "    col(\"product_id\").cast(IntegerType()),\n",
    "    col(\"product_qty\").cast(FloatType()) # Usando quantidade como 'rating' implícito\n",
    ").na.drop() # Remover linhas onde customer_id ou product_id são nulos após cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "01b2b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear colunas para o padrão do ALS\n",
    "als_data = als_data.withColumnRenamed(\"customer_id\", \"userCol\") \\\n",
    "                   .withColumnRenamed(\"product_id\", \"itemCol\") \\\n",
    "                   .withColumnRenamed(\"product_qty\", \"ratingCol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "113ec314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados em treino e teste (opcional, mas bom para avaliação)\n",
    "(training, test) = als_data.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ad47a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir e treinar o modelo ALS\n",
    "# Parâmetros podem ser ajustados/otimizados via validação cruzada\n",
    "als = ALS(maxIter=10, regParam=0.1, userCol=\"userCol\", itemCol=\"itemCol\", ratingCol=\"ratingCol\",\n",
    "          coldStartStrategy=\"drop\", # Descarta usuários/itens frios nas predições\n",
    "          implicitPrefs=True, # Indicar que os 'ratings' são implícitos (frequência de compra)\n",
    "          alpha=1.0) # Parâmetro alpha para implicitPrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8b4a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97115fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gerando Top 5 recomendações por usuário...\n"
     ]
    }
   ],
   "source": [
    "# Gerar Top 5 recomendações para cada usuário\n",
    "user_recs = als_model.recommendForAllUsers(5) # Top 5 itens por usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2f272ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Recomendações por Usuário (IDs de Produto):\n",
      "+-------+------------------------------------------------------------------------------------------------------------------+\n",
      "|userCol|recommendations                                                                                                   |\n",
      "+-------+------------------------------------------------------------------------------------------------------------------+\n",
      "|580    |[{5674, 0.7960533}, {19808, 0.69510657}, {20412, 0.66070056}, {14536, 0.595119}, {17766, 0.53452855}]             |\n",
      "|470    |[{5674, 0.9324528}, {19808, 0.9109026}, {20412, 0.86321026}, {14536, 0.66503054}, {17766, 0.6208252}]             |\n",
      "|430    |[{2678, 1.2318783}, {13610, 1.1846702}, {16620, 1.1562933}, {13609, 1.1465605}, {5435, 1.1372563}]                |\n",
      "|450    |[{12936, 0.5012792}, {13437, 0.34588683}, {12913, 0.34109274}, {12926, 0.28449896}, {1134, 0.23210894}]           |\n",
      "|80     |[{6685, 1.0058322}, {11668, 1.0002928}, {5095, 0.9977284}, {20120, 0.9539344}, {2082, 0.9499177}]                 |\n",
      "|60     |[{2786, 1.3900974}, {13594, 1.2252946}, {1136, 1.189971}, {14028, 1.0633547}, {18645, 1.0141095}]                 |\n",
      "|260    |[{14028, 2.2620595E-6}, {21651, 2.2177148E-6}, {10315, 1.794768E-6}, {18661, 1.7643488E-6}, {20178, 1.7021983E-6}]|\n",
      "|270    |[{15167, 1.0274922}, {10181, 0.82871175}, {2786, 0.5366892}, {15468, 0.4755975}, {10945, 0.40925878}]             |\n",
      "|690    |[{963, 0.07916315}, {13449, 0.078119546}, {4064, 0.07513258}, {13746, 0.07380508}, {10181, 0.07375098}]           |\n",
      "|30     |[{4189, 0.9975587}, {11668, 0.9004975}, {16596, 0.88010305}, {6786, 0.8770045}, {5542, 0.86225116}]               |\n",
      "+-------+------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Recomendações por Usuário (IDs de Produto):\")\n",
    "user_recs.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84ce206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatar as recomendações para melhor visualização (ex: explodir a lista)\n",
    "user_recs_formatted = user_recs.withColumn(\"rec_exp\", expr(\"explode(recommendations)\")) \\\n",
    "                               .select(\"userCol\", col(\"rec_exp.itemCol\").alias(\"product_id\"), col(\"rec_exp.rating\").alias(\"predicted_rating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d140ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendações formatadas (Usuário, Produto ID, Rating Predito):\n",
      "+-------+----------+----------------+\n",
      "|userCol|product_id|predicted_rating|\n",
      "+-------+----------+----------------+\n",
      "|    580|      5674|       0.7960533|\n",
      "|    580|     19808|      0.69510657|\n",
      "|    580|     20412|      0.66070056|\n",
      "|    580|     14536|        0.595119|\n",
      "|    580|     17766|      0.53452855|\n",
      "|    470|      5674|       0.9324528|\n",
      "|    470|     19808|       0.9109026|\n",
      "|    470|     20412|      0.86321026|\n",
      "|    470|     14536|      0.66503054|\n",
      "|    470|     17766|       0.6208252|\n",
      "|    430|      2678|       1.2318783|\n",
      "|    430|     13610|       1.1846702|\n",
      "|    430|     16620|       1.1562933|\n",
      "|    430|     13609|       1.1465605|\n",
      "|    430|      5435|       1.1372563|\n",
      "|    450|     12936|       0.5012792|\n",
      "|    450|     13437|      0.34588683|\n",
      "|    450|     12913|      0.34109274|\n",
      "|    450|     12926|      0.28449896|\n",
      "|    450|      1134|      0.23210894|\n",
      "+-------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recomendações formatadas (Usuário, Produto ID, Rating Predito):\")\n",
    "user_recs_formatted.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb7e8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar com nomes dos produtos para tornar as recomendações mais legíveis\n",
    "# Selecionar apenas id e nome do produto para o join\n",
    "df_produtos_nomes = df_produtos.select(col(\"product_id\").cast(IntegerType()), \"post_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f610846",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recs_final = user_recs_formatted.join(df_produtos_nomes, user_recs_formatted.product_id == df_produtos_nomes.product_id, \"left\") \\\n",
    "                                  .select(\n",
    "    col(\"userCol\"),\n",
    "    df_produtos_nomes.product_id.alias(\"product_id\"),\n",
    "    col(\"post_title\"),\n",
    "    col(\"predicted_rating\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e04f9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar para mostrar top 5 por usuário de forma mais clara\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc31cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.partitionBy(\"userCol\").orderBy(col(\"predicted_rating\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e547648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11cf70a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recs_grouped = user_recs_final \\\n",
    "    .withColumn(\"rank\", rank().over(window_spec)) \\\n",
    "    .where(col(\"rank\") <= 5) \\\n",
    "    .groupBy(\"userCol\") \\\n",
    "    .agg(collect_list(struct(\"product_id\", \"post_title\", \"predicted_rating\")).alias(\"top_5_recomendacoes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83402658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|userCol|top_5_recomendacoes                                                                                                                                                                                                                                                         |\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|26     |[{4429, ASUS ROG ALLY 7 GAMING CONSOLE, 1.1409168}, {1136, DELL G15 G5535-A643GRY-PUS, 1.1205758}, {4376, HP ENVY X360 15 EW1073CL, 0.9990194}, {10212, APPLE IMAC 2021, 0.9826725}, {10945, HP VICTUS 15-FB1013DX, 0.97994095}]                                            |\n",
      "|29     |[{13594, HP VICTUS 15-FB2082WM, 0.98641443}, {12956, LENOVO IDEAPAD SLIM 3 15ABR8-SM, 0.9700386}, {6685, ACER ASPIRE 3 A315-24PT-R90Z, 0.9009697}, {14549, HP VICTUS 15-FB2082WM, 0.847847}, {17242, DELL G15 G5530, 0.8365317}]                                            |\n",
      "|30     |[{4189, HP ENVY X360 14-ES0013DX, 0.9975587}, {11668, ACER ASPIRE 3 A315-24PT-R90Z, 0.9004975}, {16596, DELL LATITUDE 3190 2-IN-1, 0.88010305}, {6786, LENOVO FLEX 5 14ABR8, 0.8770045}, {5542, HP BIWIN S1 SERIES 8GB DDR4, 0.86225116}]                                   |\n",
      "|43     |[{17753, ASUS ZENBOOK Q415MA-U5512-SM, 1.0093621}, {1136, DELL G15 G5535-A643GRY-PUS, 0.9584695}, {13437, GEIL RGB POLARIS DDR5 16GBX2-SM, 0.9564168}, {19561, ACER PREDATOR HELIOS NEO PHN16-72-99PA-SM, 0.95605856}, {10315, ASUS TUF F15 FX507VI GAMING, 0.90391904}]    |\n",
      "|60     |[{2786, MSI CYBORG A13VE-218US, 1.3900974}, {13594, HP VICTUS 15-FB2082WM, 1.2252946}, {1136, DELL G15 G5535-A643GRY-PUS, 1.189971}, {14028, ASROCK A320M-ITX, 1.0633547}, {18645, ASUS TUF F15 FX507VV-WS74, 1.0141095}]                                                   |\n",
      "|69     |[{13442, GEIL EVO POTENZA RED DDR4 16GBX1-SM, 0.0065505714}, {2418, LENOVO IDEAPAD 1 14IGL7, 0.0046099587}, {18645, ASUS TUF F15 FX507VV-WS74, 0.0035689955}, {14288, POS IMPRESORA TERMICA 38T-SM, 0.0035672989}, {5669, POS-D IMPRESORA DE ETIQUETAS LP300X, 0.003345328}]|\n",
      "|72     |[{13442, GEIL EVO POTENZA RED DDR4 16GBX1-SM, 8.454811E-12}, {2418, LENOVO IDEAPAD 1 14IGL7, 6.673985E-12}, {14288, POS IMPRESORA TERMICA 38T-SM, 4.568808E-12}, {5669, POS-D IMPRESORA DE ETIQUETAS LP300X, 4.2845194E-12}, {17242, DELL G15 G5530, 3.706169E-12}]         |\n",
      "|75     |[{17753, ASUS ZENBOOK Q415MA-U5512-SM, 0.27504304}, {12908, APPLE MACBOOK AIR 13 GOLD-SM, 0.24564487}, {7119, SAMSUNG GALAXY TAB S9 FE WIFI 6GB 128GB SILVER, 0.22868447}, {5435, ASUS ROG STRIX G17 G713PV-WS94, 0.1990553}, {2418, LENOVO IDEAPAD 1 14IGL7, 0.18921901}]  |\n",
      "|80     |[{6685, ACER ASPIRE 3 A315-24PT-R90Z, 1.0058322}, {11668, ACER ASPIRE 3 A315-24PT-R90Z, 1.0002928}, {5095, HP PAVILION PLUS 14-EH1047NR, 0.9977284}, {20120, LENOVO LEGION SLIM 5, 0.9539344}, {2082, LENOVO YOGA 6, 0.9499177}]                                            |\n",
      "|119    |[{5674, ONN GOOGLE TV 4K STREAMING BOX, 1.012403}, {20486, DELL LATITUDE 7320 TABLET, 1.0121863}, {14536, ONN GOOGLE TV 4K STREAMING BOX, 1.0108497}, {7116, SAMSUNG GALAXY TAB S9 FE WIFI 8GB 256GB GREEN, 1.0094498}, {1155, JBL BOOMBOX 3 BLACK, 1.0060269}]             |\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_recs_grouped.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512b1ab",
   "metadata": {},
   "source": [
    "Avaliação do Modelo ALS (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1407988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "82268322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+------------+\n",
      "|userCol|itemCol|ratingCol|  prediction|\n",
      "+-------+-------+---------+------------+\n",
      "|     26|   1145|      1.0| 0.063379936|\n",
      "|     26|   5178|      1.0|  0.10409063|\n",
      "|     26|   5428|      5.0|-0.073462605|\n",
      "|     26|   5435|      3.0|  0.93182766|\n",
      "|     26|  11832|      1.0|  0.10006907|\n",
      "+-------+-------+---------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Root-Mean-Square Error (RMSE) no conjunto de teste = 75.39323965352727\n"
     ]
    }
   ],
   "source": [
    "predictions_test = als_model.transform(test)\n",
    "predictions_test.show(5)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"ratingCol\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions_test.na.drop(subset=[\"prediction\"]))\n",
    "\n",
    "print(f\"\\nRoot-Mean-Square Error (RMSE) no conjunto de teste = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0fa43ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE):    14.5559\n"
     ]
    }
   ],
   "source": [
    "evaluator_mae = RegressionEvaluator(metricName=\"mae\", labelCol=\"ratingCol\", predictionCol=\"prediction\")\n",
    "mae = evaluator_mae.evaluate(predictions_test)\n",
    "print(f\"Mean Absolute Error (MAE):    {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eedcdb",
   "metadata": {},
   "source": [
    "#### CHURN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2466b7",
   "metadata": {},
   "source": [
    "7. Modelo de Previsão de Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6afe14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import datediff, current_date, lit, avg as spark_avg, count as spark_count, max as spark_max, struct\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e4f3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Definição de Churn e Criação de Labels\n",
    "# Definir churn: Cliente que não fez compra nos últimos X dias (ex: 90 dias)\n",
    "# Este valor pode ser ajustado com base no conhecimento do negócio\n",
    "churn_threshold_days = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6c03077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar a tabela RFM que já tem a Recência (dias desde a última compra)\n",
    "# Se Recencia > churn_threshold_days, então churn = 1, senão 0\n",
    "# Certificar que rfm_final está disponível\n",
    "if 'rfm_final' not in locals():\n",
    "    print(\"Erro: Tabela rfm_final não encontrada. Execute a etapa RFM primeiro.\")\n",
    "    # Adicionar código para recarregar ou recalcular rfm_final se necessário\n",
    "    # Por exemplo:\n",
    "    # rfm_r = df_ordens.groupBy(\"customer_id\").agg(spark_min(\"recencia_ordem_dias\").alias(\"Recencia\"))\n",
    "    # rfm_f = df_ordens.groupBy(\"customer_id\").agg(countDistinct(\"order_id\").alias(\"Frequencia\"))\n",
    "    # rfm_m = df_ordens.groupBy(\"customer_id\").agg(spark_sum(\"product_gross_revenue\").alias(\"Monetario\"))\n",
    "    # rfm_final = rfm_r.join(rfm_f, \"customer_id\", \"inner\").join(rfm_m, \"customer_id\", \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0259e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_labels = rfm_final.withColumn(\"churn_label\",\n",
    "                                    when(col(\"Recencia\") > churn_threshold_days, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "842012db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definindo churn como inatividade > 90 dias.\n",
      "+-----------+-----+\n",
      "|churn_label|count|\n",
      "+-----------+-----+\n",
      "|          1|   80|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Definindo churn como inatividade > {churn_threshold_days} dias.\")\n",
    "churn_labels.groupBy(\"churn_label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "270120a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Feature Engineering Adicional\n",
    "# Juntar com df_clientes para obter 'dias_desde_registro'\n",
    "# Certificar que df_clientes está disponível e processado\n",
    "if 'df_clientes' not in locals() or 'dias_desde_registro' not in df_clientes.columns:\n",
    "     print(\"Erro: df_clientes ou coluna 'dias_desde_registro' não encontrada.\")\n",
    "     # Recarregar/reprocessar df_clientes se necessário\n",
    "     # df_clientes = spark.read.csv(path_clientes, header=True, inferSchema=True, sep=',')\n",
    "     # df_clientes = df_clientes.dropDuplicates(['user_id'])\n",
    "     # df_clientes = df_clientes.withColumn(\"user_registered_ts\", to_timestamp(col(\"user_registered\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "     # df_clientes = df_clientes.withColumn(\"dias_desde_registro\", datediff(current_date(), col(\"user_registered_ts\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f221022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data = churn_labels.join(df_clientes.select(col(\"user_id\").alias(\"customer_id_ref\"), \"dias_desde_registro\"),\n",
    "                               churn_labels.customer_id == col(\"customer_id_ref\"), \"left\") \\\n",
    "                         .select(\"customer_id\", \"Recencia\", \"Frequencia\", \"Monetario\", \"dias_desde_registro\", \"churn_label\") \\\n",
    "                         .na.fill(0, subset=[\"dias_desde_registro\"]) # Preencher nulos em dias_desde_registro (ex: se cliente não encontrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed95efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados preparados para modelo de churn:\n",
      "+-----------+--------+----------+-----------------+-------------------+-----------+\n",
      "|customer_id|Recencia|Frequencia|        Monetario|dias_desde_registro|churn_label|\n",
      "+-----------+--------+----------+-----------------+-------------------+-----------+\n",
      "|        737|     134|         2|          4715.28|                  0|          1|\n",
      "|        516|     154|         1|           1044.3|                  0|          1|\n",
      "|        580|     197|         2|           1770.0|                  0|          1|\n",
      "|        513|     198|        13|50761.23999999999|                  0|          1|\n",
      "|        613|     210|         1|           1534.0|                  0|          1|\n",
      "+-----------+--------+----------+-----------------+-------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dados preparados para modelo de churn:\")\n",
    "churn_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a1f0b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 Preparação para Modelagem (VectorAssembler, Scaler, Split)\n",
    "# Colunas de features\n",
    "feature_cols = [\"Recencia\", \"Frequencia\", \"Monetario\", \"dias_desde_registro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ba93366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar vetor de features\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_raw\", handleInvalid=\"skip\") # Skip rows with nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90164802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar features numéricas (importante para regressão logística)\n",
    "scaler_churn = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\", withStd=True, withMean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b2198c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar pipeline para pré-processamento\n",
    "preprocess_pipeline = Pipeline(stages=[assembler, scaler_churn])\n",
    "preprocess_model = preprocess_pipeline.fit(churn_data)\n",
    "final_churn_data = preprocess_model.transform(churn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2121db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar colunas finais e renomear label\n",
    "final_churn_data = final_churn_data.select(col(\"customer_id\"), col(\"features\"), col(\"churn_label\").alias(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1bdf8267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados finais com features escaladas e label:\n",
      "+-----------+------------------------------------------------------------------------------------+-----+\n",
      "|customer_id|features                                                                            |label|\n",
      "+-----------+------------------------------------------------------------------------------------+-----+\n",
      "|737        |[-1.2204026035000965,-0.33474376723009847,-0.34684949808465804,-0.6423398862187408] |1    |\n",
      "|516        |[-0.9020713081626082,-0.3828218666527338,-0.40099505711315014,-0.6423398862187408]  |1    |\n",
      "|580        |[-0.21765902318700828,-0.33474376723009847,-0.39029125807665943,-0.6423398862187408]|1    |\n",
      "|513        |[-0.20174245842013386,0.1941153264188905,0.3323109019184983,-0.6423398862187408]    |1    |\n",
      "|613        |[-0.010743681217640863,-0.3828218666527338,-0.39377216833242873,-0.6423398862187408]|1    |\n",
      "+-----------+------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dados finais com features escaladas e label:\")\n",
    "final_churn_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bc099b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros de treino: 63, Registros de teste: 17\n",
      "Modelo de Regressão Logística treinado.\n",
      "Predições no conjunto de teste:\n",
      "+-----------+-----+-----------+----------+\n",
      "|customer_id|label|probability|prediction|\n",
      "+-----------+-----+-----------+----------+\n",
      "|30         |1    |[0.0,1.0]  |1.0       |\n",
      "|72         |1    |[0.0,1.0]  |1.0       |\n",
      "|80         |1    |[0.0,1.0]  |1.0       |\n",
      "|172        |1    |[0.0,1.0]  |1.0       |\n",
      "|244        |1    |[0.0,1.0]  |1.0       |\n",
      "|260        |1    |[0.0,1.0]  |1.0       |\n",
      "|279        |1    |[0.0,1.0]  |1.0       |\n",
      "|327        |1    |[0.0,1.0]  |1.0       |\n",
      "|432        |1    |[0.0,1.0]  |1.0       |\n",
      "|435        |1    |[0.0,1.0]  |1.0       |\n",
      "+-----------+-----+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Área sob a curva ROC (AUC) no conjunto de teste: 1.0\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Verificar se há dados suficientes após pré-processamento\n",
    "if final_churn_data.count() == 0:\n",
    "    print(\"Erro: Nenhum dado restante após pré-processamento para o modelo de churn.\")\n",
    "else:\n",
    "    # Dividir em treino e teste\n",
    "    (train_data, test_data) = final_churn_data.randomSplit([0.8, 0.2], seed=42)\n",
    "    print(f\"Registros de treino: {train_data.count()}, Registros de teste: {test_data.count()}\")\n",
    "\n",
    "    # 7.4 Treinamento do Modelo (Ex: Regressão Logística)\n",
    "    if train_data.count() > 0:\n",
    "        lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "        lr_model = lr.fit(train_data)\n",
    "        print(\"Modelo de Regressão Logística treinado.\")\n",
    "\n",
    "        # 7.5 Avaliação do Modelo\n",
    "        if test_data.count() > 0:\n",
    "            predictions_lr = lr_model.transform(test_data)\n",
    "            print(\"Predições no conjunto de teste:\")\n",
    "            predictions_lr.select(\"customer_id\", \"label\", \"probability\", \"prediction\").show(10, truncate=False)\n",
    "\n",
    "            # Avaliar usando AUC\n",
    "            evaluator_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "            # Lidar com possíveis NaNs na coluna de predição se houver\n",
    "            auc = evaluator_auc.evaluate(predictions_lr.na.drop(subset=[\"rawPrediction\"]))\n",
    "            print(f\"Área sob a curva ROC (AUC) no conjunto de teste: {auc}\")\n",
    "\n",
    "            # Avaliar usando outras métricas (Accuracy, Precision, Recall, F1)\n",
    "            evaluator_multi = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "            accuracy = evaluator_multi.evaluate(predictions_lr, {evaluator_multi.metricName: \"accuracy\"})\n",
    "            precision = evaluator_multi.evaluate(predictions_lr, {evaluator_multi.metricName: \"weightedPrecision\"})\n",
    "            recall = evaluator_multi.evaluate(predictions_lr, {evaluator_multi.metricName: \"weightedRecall\"})\n",
    "            f1 = evaluator_multi.evaluate(predictions_lr, {evaluator_multi.metricName: \"f1\"})\n",
    "\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"F1 Score: {f1}\")\n",
    "        else:\n",
    "            print(\"Não há dados de teste suficientes para avaliação.\")\n",
    "    else:\n",
    "        print(\"Não há dados de treino suficientes para treinar o modelo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c73a7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há predições válidas para avaliação após remover NaNs.\n"
     ]
    }
   ],
   "source": [
    "# 1. Avaliador AUC e AUC-PR\n",
    "evaluator_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "evaluator_pr = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderPR\")\n",
    "\n",
    "# Lidar com possíveis NaNs na coluna de predição se houver (ex: coldStartStrategy)\n",
    "valid_predictions = predictions_lr.na.drop(subset=[\"rawPrediction\", \"prediction\", \"label\"])\n",
    "\n",
    "if valid_predictions.count() == 0:\n",
    "    print(\"Não há predições válidas para avaliação após remover NaNs.\")\n",
    "else: \n",
    "    print(\"Há predições válidas para avaliação após remover NaNs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7df2b255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Área sob a Curva ROC (AUC): 1.0000\n",
      "Área sob a Curva Precision-Recall (AUC-PR): 1.0000\n"
     ]
    }
   ],
   "source": [
    "auc_score = evaluator_auc.evaluate(valid_predictions)\n",
    "pr_auc_score = evaluator_pr.evaluate(valid_predictions)\n",
    "print(f\"Área sob a Curva ROC (AUC): {auc_score:.4f}\")\n",
    "print(f\"Área sob a Curva Precision-Recall (AUC-PR): {pr_auc_score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4eaa5c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 1.0000\n",
      "Precision Ponderada: 1.0000\n",
      "Recall Ponderado: 1.0000\n",
      "F1-Score Ponderado: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 2. Avaliador Multiclasse para Accuracy, Precision, Recall, F1\n",
    "evaluator_multi = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator_multi.evaluate(valid_predictions, {evaluator_multi.metricName: \"accuracy\"})\n",
    "precision_w = evaluator_multi.evaluate(valid_predictions, {evaluator_multi.metricName: \"weightedPrecision\"})\n",
    "recall_w = evaluator_multi.evaluate(valid_predictions, {evaluator_multi.metricName: \"weightedRecall\"})\n",
    "f1_w = evaluator_multi.evaluate(valid_predictions, {evaluator_multi.metricName: \"f1\"})\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision Ponderada: {precision_w:.4f}\")\n",
    "print(f\"Recall Ponderado: {recall_w:.4f}\")\n",
    "print(f\"F1-Score Ponderado: {f1_w:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "24ef997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 1: Precision = 1.0000, Recall = 1.0000, F1 = 1.0000\n",
      "\n",
      "-- Métricas por Classe --\n",
      "\n",
      "-- Métricas por Classe (presentes nos dados) --\n",
      "Label 1: Precision = 1.0000, Recall = 1.0000, F1 = 1.0000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Verifique as labels presentes\n",
    "present_labels = valid_predictions.select(\"label\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "evaluator_multi = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "for label in present_labels:\n",
    "    precision = evaluator_multi.evaluate(valid_predictions, {\n",
    "        evaluator_multi.metricName: \"precisionByLabel\",\n",
    "        evaluator_multi.metricLabel: label\n",
    "    })\n",
    "    recall = evaluator_multi.evaluate(valid_predictions, {\n",
    "        evaluator_multi.metricName: \"recallByLabel\",\n",
    "        evaluator_multi.metricLabel: label\n",
    "    })\n",
    "    f1 = evaluator_multi.evaluate(valid_predictions, {\n",
    "        evaluator_multi.metricName: \"f1\",\n",
    "        evaluator_multi.metricLabel: label\n",
    "    })\n",
    "\n",
    "    print(f\"Label {label}: Precision = {precision:.4f}, Recall = {recall:.4f}, F1 = {f1:.4f}\")\n",
    "\n",
    "# 3. Métricas por Classe\n",
    "print(\"\\n-- Métricas por Classe --\")\n",
    "labels = [0.0, 1.0]\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "# 🔍 Verifique quais classes realmente estão presentes\n",
    "labels_presentes = valid_predictions.select(\"label\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "print(\"\\n-- Métricas por Classe (presentes nos dados) --\")\n",
    "for label in sorted(labels_presentes):\n",
    "    evaluator.setMetricLabel(label)\n",
    "\n",
    "    evaluator.setMetricName(\"precisionByLabel\")\n",
    "    precision = evaluator.evaluate(valid_predictions)\n",
    "\n",
    "    evaluator.setMetricName(\"recallByLabel\")\n",
    "    recall = evaluator.evaluate(valid_predictions)\n",
    "\n",
    "    evaluator.setMetricName(\"f1\")\n",
    "    f1 = evaluator.evaluate(valid_predictions)\n",
    "\n",
    "    print(f\"Label {label}: Precision = {precision:.4f}, Recall = {recall:.4f}, F1 = {f1:.4f}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fe65bea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Matriz de Confusão --\n",
      "                 Predito 0 | Predito 1\n",
      "Real 0 (Não Churn):     0     |    0    \n",
      "Real 1 (Churn):         0     |    17   \n"
     ]
    }
   ],
   "source": [
    "# 4. Matriz de Confusão (Cálculo com PySpark)\n",
    "print(\"\\n-- Matriz de Confusão --\")\n",
    "# Calcula TP, TN, FP, FN diretamente\n",
    "tp = valid_predictions.filter(\"label = 1.0 AND prediction = 1.0\").count()\n",
    "tn = valid_predictions.filter(\"label = 0.0 AND prediction = 0.0\").count()\n",
    "fp = valid_predictions.filter(\"label = 0.0 AND prediction = 1.0\").count()\n",
    "fn = valid_predictions.filter(\"label = 1.0 AND prediction = 0.0\").count()\n",
    "\n",
    "print(f\"                 Predito 0 | Predito 1\")\n",
    "print(f\"Real 0 (Não Churn):  {tn:^8} | {fp:^8}\")\n",
    "print(f\"Real 1 (Churn):      {fn:^8} | {tp:^8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc32010",
   "metadata": {},
   "source": [
    "Próximo passo: Finalizar e entregar o notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b308e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Finalizar SparkSession\n",
    "spark.stop()\n",
    "print(\"SparkSession finalizada.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
